{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb5bd6a-27b9-49bb-af17-3ace10307d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout, add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b020f21-605f-4bbd-a165-9fab75b3945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1              A girl going into a wooden building .  \n",
      "2   A little girl climbing into a wooden playhouse .  \n",
      "3  A little girl climbing the stairs to her playh...  \n",
      "4  A little girl in a pink dress going into a woo...  \n"
     ]
    }
   ],
   "source": [
    "captions_path = r\"C:\\Users\\kokar\\Downloads\\archive (42)\\captions.txt\"\n",
    "images_path = \"C:/Users/kokar/Downloads/archive (42)/Images/\"\n",
    "df = pd.read_csv(captions_path)\n",
    "df.columns = [\"image\", \"caption\"]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b28b408-24b3-47cc-9f61-3858696c7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = text.replace(\"\\n\", \" \")  # Remove new lines\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    text = text.strip()  # Trim spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ab9e3a-b24b-4f22-a05a-a2c50f9cbf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"caption\"] = df[\"caption\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0619e7b-dd15-4aac-8978-ee8d71600fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a girl going into a wooden building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl climbing into a wooden playhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>a man in a pink shirt climbs a rock face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>a man is rock climbing high in the air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>a person in a red shirt climbing up a rock fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>a rock climber in a red shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>a rock climber practices on a rock climbing wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  \\\n",
       "0      1000268201_693b08cb0e.jpg   \n",
       "1      1000268201_693b08cb0e.jpg   \n",
       "2      1000268201_693b08cb0e.jpg   \n",
       "3      1000268201_693b08cb0e.jpg   \n",
       "4      1000268201_693b08cb0e.jpg   \n",
       "...                          ...   \n",
       "40450   997722733_0cb5439472.jpg   \n",
       "40451   997722733_0cb5439472.jpg   \n",
       "40452   997722733_0cb5439472.jpg   \n",
       "40453   997722733_0cb5439472.jpg   \n",
       "40454   997722733_0cb5439472.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0      a child in a pink dress is climbing up a set o...  \n",
       "1                    a girl going into a wooden building  \n",
       "2         a little girl climbing into a wooden playhouse  \n",
       "3      a little girl climbing the stairs to her playh...  \n",
       "4      a little girl in a pink dress going into a woo...  \n",
       "...                                                  ...  \n",
       "40450           a man in a pink shirt climbs a rock face  \n",
       "40451             a man is rock climbing high in the air  \n",
       "40452  a person in a red shirt climbing up a rock fac...  \n",
       "40453                      a rock climber in a red shirt  \n",
       "40454   a rock climber practices on a rock climbing wall  \n",
       "\n",
       "[40455 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "987e0e56-fbff-45be-9ae9-26f3d0fc06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"caption\"] = df[\"caption\"].apply(lambda x: \"<start> \" + x + \" <end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c08168-a9cb-409a-899c-c505218fb3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>&lt;start&gt; a child in a pink dress is climbing up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>&lt;start&gt; a girl going into a wooden building &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>&lt;start&gt; a little girl climbing into a wooden p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>&lt;start&gt; a little girl climbing the stairs to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>&lt;start&gt; a little girl in a pink dress going in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>&lt;start&gt; a man in a pink shirt climbs a rock fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>&lt;start&gt; a man is rock climbing high in the air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>&lt;start&gt; a person in a red shirt climbing up a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>&lt;start&gt; a rock climber in a red shirt &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>&lt;start&gt; a rock climber practices on a rock cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  \\\n",
       "0      1000268201_693b08cb0e.jpg   \n",
       "1      1000268201_693b08cb0e.jpg   \n",
       "2      1000268201_693b08cb0e.jpg   \n",
       "3      1000268201_693b08cb0e.jpg   \n",
       "4      1000268201_693b08cb0e.jpg   \n",
       "...                          ...   \n",
       "40450   997722733_0cb5439472.jpg   \n",
       "40451   997722733_0cb5439472.jpg   \n",
       "40452   997722733_0cb5439472.jpg   \n",
       "40453   997722733_0cb5439472.jpg   \n",
       "40454   997722733_0cb5439472.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0      <start> a child in a pink dress is climbing up...  \n",
       "1      <start> a girl going into a wooden building <end>  \n",
       "2      <start> a little girl climbing into a wooden p...  \n",
       "3      <start> a little girl climbing the stairs to h...  \n",
       "4      <start> a little girl in a pink dress going in...  \n",
       "...                                                  ...  \n",
       "40450  <start> a man in a pink shirt climbs a rock fa...  \n",
       "40451  <start> a man is rock climbing high in the air...  \n",
       "40452  <start> a person in a red shirt climbing up a ...  \n",
       "40453        <start> a rock climber in a red shirt <end>  \n",
       "40454  <start> a rock climber practices on a rock cli...  \n",
       "\n",
       "[40455 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1df870e-2ca5-4b48-a758-4335156a51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1000268201_693b08cb0e.jpg', ['<start> a child in a pink dress is climbing up a set of stairs in an entry way <end>', '<start> a girl going into a wooden building <end>', '<start> a little girl climbing into a wooden playhouse <end>', '<start> a little girl climbing the stairs to her playhouse <end>', '<start> a little girl in a pink dress going into a wooden cabin <end>']), ('1001773457_577c3a7d70.jpg', ['<start> a black dog and a spotted dog are fighting <end>', '<start> a black dog and a tricolored dog playing with each other on the road <end>', '<start> a black dog and a white dog with brown spots are staring at each other in the street <end>', '<start> two dogs of different breeds looking at each other on the road <end>', '<start> two dogs on pavement moving toward each other <end>'])]\n"
     ]
    }
   ],
   "source": [
    "image_captions = {}\n",
    "for _,row in df.iterrows():\n",
    "    # print(row,_)\n",
    "    img, caption = row[\"image\"], row[\"caption\"]\n",
    "    if img not in image_captions:\n",
    "        image_captions[img] = []\n",
    "        # print(image_captions)\n",
    "    image_captions[img].append(caption)\n",
    "print(list(image_captions.items())[:2])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9aba03-820d-4544-be47-66127a5309db",
   "metadata": {},
   "source": [
    "Understanding InceptionV3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d98a2-ef06-477c-931e-22d2cbcc65dc",
   "metadata": {},
   "source": [
    "InceptionV3 is a deep convolutional neural network (CNN) designed for image classification.\n",
    "It was introduced by Google and is well-known for its efficiency and accuracy.\n",
    "The model was trained on the ImageNet dataset, which contains over 14 million images across 1,000 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e4c21-2247-4f32-90ec-51b93d887fc3",
   "metadata": {},
   "source": [
    "What is avg_pool in InceptionV3?\n",
    "\n",
    "In InceptionV3, avg_pool refers to the Global Average Pooling (GAP) layer, which is the second-last layer of the model, just before the final classification layer.\n",
    "\n",
    "Understanding Global Average Pooling (avg_pool)\n",
    "\n",
    "The avg_pool layer reduces the spatial dimensions (height & width) of the feature maps to 1x1 per channel by computing the average of each feature map.\n",
    "Instead of using a fully connected layer (which has many parameters), Global Average Pooling significantly reduces the number of parameters and helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dff491fd-38b1-4d43-bc3e-01f298c25b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=InceptionV3(weights=\"imagenet\")\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer(\"avg_pool\").output)\n",
    "def extract_features(img_path):\n",
    "    img = Image.open(img_path).resize((299, 299))  # Resize for InceptionV3\n",
    "    img = np.array(img) / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    # Expand Dimensions (np.expand_dims(img, axis=0))\n",
    "    # Converts from shape (299, 299, 3) to (1, 299, 299, 3) (adds batch dimension).\n",
    "    img = preprocess_input(img)  # Apply InceptionV3 preprocessing\n",
    "    features = model.predict(img)  # Extract features\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88af09cb-91bb-4cf5-b374-9432b4de4408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Feature Shape: (1, 2048)\n"
     ]
    }
   ],
   "source": [
    "simple_image=list(image_captions.keys())[0]\n",
    "image_features = extract_features(os.path.join(images_path, sample_image))\n",
    "\n",
    "print(f\"Feature Shape: {image_features.shape}\")\n",
    "# print(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e0c7211-585c-4503-a8cc-1f7113c1c71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> a child in a pink dress is climbing up a set of stairs in an entry way <end>'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer().fit_on_texts(all_captions) → This creates a vocabulary of unique words from all captions.\n",
    "# tokenizer.texts_to_sequences(captions) → Converts each caption into a sequence of integers (word indices).\n",
    "all_caption=[]\n",
    "for caption in image_captions.values():\n",
    "    all_caption.extend(caption)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_caption)\n",
    "all_caption[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b52d066-0695-4e4e-81fd-8af741554047",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab7f10f7-3338-4a98-afc6-750029eb0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_caption(captions):\n",
    "    return tokenizer.texts_to_sequences(captions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4114ea0f-9215-47ab-b783-6d78deaa5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_sequences = {img: encode_caption(caps) for img, caps in image_captions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33a899-3323-4fd4-bffe-14559364a1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
